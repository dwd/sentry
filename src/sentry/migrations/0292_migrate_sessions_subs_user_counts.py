# Generated by Django 2.2.28 on 2022-06-15 11:14
# Largely copied from https://github.com/getsentry/getsentry/blob/89ff1453be755ddef31f2b99de09bd03badeb25e/getsentry/migrations/0141_migrate_sessions_subs_to_metrics.py

import logging

from django.db import migrations, transaction

from sentry.incidents.tasks import INCIDENTS_SNUBA_SUBSCRIPTION_TYPE
from sentry.new_migrations.migrations import CheckedMigration
from sentry.sentry_metrics import indexer
from sentry.snuba.dataset import EntityKey
from sentry.snuba.entity_subscription import map_aggregate_to_entity_key
from sentry.snuba.models import QueryDatasets
from sentry.snuba.tasks import _create_in_snuba, _delete_from_snuba
from sentry.utils.query import RangeQuerySetWrapperWithProgressBar


def create_subscription_in_snuba(subscription):
    subscription.subscription_id = _create_in_snuba(subscription)
    subscription.save()


def delete_subscription_from_snuba(subscription, query_dataset):
    entity_key: EntityKey = map_aggregate_to_entity_key(
        query_dataset, subscription.snuba_query.aggregate
    )
    _delete_from_snuba(
        query_dataset,
        subscription.subscription_id,
        entity_key,
    )
    subscription.delete()


@property
def event_types(self):
    import ipdb

    ipdb.set_trace()
    return [type.event_type for type in self.snubaqueryeventtype_set.all()]


def migrate_sessions_subscriptions_to_metrics(apps, schema_editor):
    QuerySubscription = apps.get_model("sentry", "QuerySubscription")
    for old_subscription in RangeQuerySetWrapperWithProgressBar(
        QuerySubscription.objects.filter(
            snuba_query__dataset=QueryDatasets.METRICS.value
        ).select_related("snuba_query")
    ):
        if old_subscription.subscription_id is not None:
            try:
                with transaction.atomic():
                    snuba_query = old_subscription.snuba_query
                    snuba_query.event_types = event_types  # TODO: why is this necessary?
                    snuba_query.save()
                    new_subscription = QuerySubscription.objects.create(
                        status=0,
                        project=old_subscription.project,
                        snuba_query=snuba_query,
                        type=INCIDENTS_SNUBA_SUBSCRIPTION_TYPE,
                    )
                    create_subscription_in_snuba(new_subscription)
                    delete_subscription_from_snuba(old_subscription, QueryDatasets.METRICS)
            except Exception:
                logging.exception(
                    "Failed to migrate session subscription to metrics",
                    extra={
                        "project": old_subscription.project.slug,
                        "subscription_id": old_subscription.id,
                        "query": old_subscription.snuba_query.query,
                        "aggregate": old_subscription.snuba_query.aggregate,
                        "time_window": old_subscription.snuba_query.time_window,
                        "resolution": old_subscription.snuba_query.resolution,
                    },
                )


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production. For
    # the most part, this should only be used for operations where it's safe to run the migration
    # after your code has deployed. So this should not be used for most operations that alter the
    # schema of a table.
    # Here are some things that make sense to mark as dangerous:
    # - Large data migrations. Typically we want these to be run manually by ops so that they can
    #   be monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   have ops run this and not block the deploy. Note that while adding an index is a schema
    #   change, it's completely safe to run the operation after the code has deployed.
    is_dangerous = False

    # This flag is used to decide whether to run this migration in a transaction or not. Generally
    # we don't want to run in a transaction here, since for long running operations like data
    # back-fills this results in us locking an increasing number of rows until we finally commit.
    atomic = False

    dependencies = [
        ("sentry", "0291_add_new_perf_indexer"),
    ]

    operations = [
        migrations.RunPython(
            migrate_sessions_subscriptions_to_metrics,
            migrations.RunPython.noop,
            hints={"tables": ["sentry_querysubscription", "sentry_snubaquery"]},
        ),
    ]
